# column bind the Health Board Areas with df.pop
df.pop <- cbind(slice.pop.areas, df.pop)
# sanity check
df.pop
df.pop <- rename(df.pop, "Health Board" = "X2")
# add Total again
df.pop$Total <- rowSums(df.pop[-1])
# name col names to lower
names(df.pop) <- tolower(names(df.pop))
# remove spaces
names(df.pop) <- sub(" ", "_", names(df.pop))
# update the col names pop
col.names.pop <- c("Health Board", slice.pop.years)
# change LHBs to shorter version.
df.pop.no.wales$health_board <- row.names1
View(df.no.wales)
View(df.pop)
knitr::opts_chunk$set(
echo = FALSE,
message = TRUE,
warning = TRUE
)
# 17076749
set.seed(17076749)
library(funModeling)
library(patchwork)
library(ggplot2)
library(readxl)
library(tidyverse)
library(dplyr)
# set the url to test
# url <- "https://nwssp.nhs.wales/ourservices/primary-care-services/primary-care-services-documents/gp-practice-analysis-docs/patient-registrations-july-2021"
# notice it doesn't end with .xlsx or .xls
# set a destination of where to save the file (with extension?)
# destfile <- "../data/data/tidytestfile"
# try to download the file with built in download.file
# download.file(url,      # what to save
#              destfile, # where to save
#              mode="wb")# wb convert it to 2 cols
# After some more research, I found some documentation saying about how
# difficult using XLSX files can be within R.
# browseURL('http://j.mp/2aFZUrJ')
# found a package rio 'R, Input, Output'
# will try to use this for the XLSX files.
# library(rio)
# import(url, format = "xlsx")
# rio still didn't fix the issue.
#rm(df)
#df <- read_excel(path = "../data/data/tidytestfile")
#head(df)
df.april20 <-
read_excel("../data/raw/NWSSP Wales AgeGender202004.xlsx",
sheet = "Sheet1")
df.july20 <-
read_excel("../data/raw/NWSSP Wales AgeGender202007.xlsx",
sheet = "Sheet1")
df.october20 <-
read_excel("../data/raw/NWSSP Wales AgeGender202010.xlsx",
sheet = "Sheet1")
df.jan21 <-
read_excel("../data/raw/NWSSP Wales AgeGender202101.xlsx",
sheet = "Sheet1")
df.april21 <-
read_excel("../data/raw/NWSSP Wales AgeGender202104Revised.xlsx",
sheet = "Sheet1")
df.july21 <-
read_excel("../data/raw/NWSSP Wales AgeGender202107.xlsx",
sheet = "Sheet1")
print(names(df.april20))
print(names(df.july20))
print(names(df.october20))
print(names(df.jan21))
print(names(df.april21))
print(names(df.july21))
# create a data frame.
df <- data.frame()
# get unique Health Boards
uHBs <- unique(df.april21$HAName)
# print LHBs
print(uHBs)
# Filter the last data frame with the unique health board
# as a new data frame
my.AB <-  filter(df.july21, HAName == uHBs[1])  # Aneurin Bevan
my.BC <-  filter(df.july21, HAName == uHBs[2])  # Betsi Cadwaladr Uni
my.HD <-  filter(df.july21, HAName == uHBs[3])  # Hywel Dda
my.CV <-  filter(df.july21, HAName == uHBs[4])  # Cardiff And Vale Uni
my.CTM <- filter(df.july21, HAName == uHBs[5]) # Cwm Taf Morgannwg UHB
my.SB <-  filter(df.july21, HAName == uHBs[6])  # Swansea Bay UHB
my.PT <-  filter(df.july21, HAName == uHBs[7])  # Powys Teaching
# check if they all have a unique OrgCode
print(paste('AB   =',  unique(my.AB$OrgCode)))
print(paste('BC   =',  unique(my.BC$OrgCode)))
print(paste('HD   =',  unique(my.HD$OrgCode)))
print(paste('CV   =',  unique(my.CV$OrgCode)))
print(paste('CTM  =',  unique(my.CTM$OrgCode)))
print(paste('SB   =',  unique(my.SB$OrgCode)))
print(paste('PT   =',  unique(my.PT$OrgCode)))
# DROP HAName
df.april21 <- df.april21[-5]
df.july21 <- df.july21[-5]
# get col names from a dataset from 2020
colNames <- names(df.april20)
# rename colnames with the same as older datasets
colnames(df.april21) <- colNames
colnames(df.july21) <- colNames
df.april20$Year <- 2020
df.april20$Month <- "April"
df.july20$Year <- 2020
df.july20$Month <- "July"
df.october20$Year <- 2020
df.october20$Month <- "October"
df.jan21$Year <- 2021
df.jan21$Month <- "January"
df.april21$Year <- 2021
df.april21$Month <- "April"
df.july21$Year <- 2021
df.july21$Month <- "July"
# Bind the datasets with rbind.
# ?rbind
df <- rbind(df.april20, df.july20, df.october20,
df.jan21, df.april21, df.july21)
# noticed the dataset added a '.'
# drop the period
df <- df[-1]
#df
#df2020 <- df %>% filter(Year == 2020)
# Replace OrgCode for LHBs.
df["OrgCode"][df["OrgCode"] == "7A1"] <- "Betsi Cadwaladr Uni"
df["OrgCode"][df["OrgCode"] == "7A2"] <- "Hywel Dda"
df["OrgCode"][df["OrgCode"] == "7A3"] <- "Swansea Bay UHB"
df["OrgCode"][df["OrgCode"] == "7A4"] <- "Cardiff And Vale Uni"
df["OrgCode"][df["OrgCode"] == "7A5"] <- "Cwm Taf Morgannwg UHB"
df["OrgCode"][df["OrgCode"] == "7A6"] <- "Aneurin Bevan"
df["OrgCode"][df["OrgCode"] == "7A7"] <- "Powys Teaching"
# Sanity check OrgCodes.
df$OrgCode %>% unique()
# rename column 3
names(df)[3] = "healthboard"
# double check the column names
names(df)
# remove original datasets
remove(df.april20, df.july20, df.october20, df.jan21, df.april21, df.july21)
# remove filtered datasets
remove(my.AB, my.BC, my.HD, my.CV,
my.CTM, my.SB,my.PT)
# the other values don't need to be removed yet.
df$Year %>% unique()
# the other values don't need to be removed yet.
df$Month %>% unique()
# Omitted
# Before moving on, lets try to add on more dataset which could help pinpoint where in each LSOA a GP is, this can be done with the datasets from the same website.
# [GP Practice Analysis Data](https://nwssp.nhs.wales/ourservices/primary-care-services/general-information/data-and-publications/gp-practice-analysis/)
# First, make a copy of the original df.
# make a copy
# dfC <- df
# gpPA <- read_xlsx("../data/gp-practice-analysis-2020.xlsx")
# gpPA %>% head()
# rename PracticeID to PracticeCode
# colnames(gpPA)[colnames(gpPA) == "PracticeID"] <- "PracticeCode"
# rename PracticeID to PracticeCode
# colnames(gpPA)[colnames(gpPA) == "Postcode"] <- "PostCode"
# now merge them by PracticeCode & Postcode
# dfC <- merge(dfC, gpPA, by = c("PracticeCode","PostCode"))
# remove spaces from postcode
df$PostCode <- gsub(" ", "", df$PostCode)
# change col names to lower.
names(df) <- names(df) %>% tolower()
# change file time from ods to xlsx outside of RStudio
# import the WIMD data as wimd.df
wimd_df <- read_excel("../data/raw/postcode-to-wimd-lookup.xlsx",
sheet = "Welsh_Postcodes")
# rename Welsh Postcode to postcode
colnames(wimd_df)[colnames(wimd_df) == "Welsh Postcode"] <- "postcode"
# change cols to lower
names(wimd_df) <- tolower(names(wimd_df))
# rename lsoa name (english)
colnames(wimd_df)[colnames(wimd_df) == "lsoa name (english)"] <- "lsoa name"
# remove "2019"  from column names (but make a note of it in plots)
colnames(wimd_df)[colnames(wimd_df) == "wimd 2019 lsoa rank"] <- "wimd lsoa rank"
colnames(wimd_df)[colnames(wimd_df) == "wimd 2019 overall decile"] <- "wimd overall decile"
colnames(wimd_df)[colnames(wimd_df) == "wimd 2019 overall quintile"] <- "wimd overall quintile"
colnames(wimd_df)[colnames(wimd_df) == "wimd 2019 overall quartile"] <- "wimd overall quartile"
# double check it worked.
names(wimd_df)
wimd_df %>% sample_n(50)
df <- inner_join(df, wimd_df, by = "postcode")
# remove spaces
names(df) <- sub(" ", "_", names(df))
# run this twice for some reason...
names(df) <- sub(" ", "_", names(df))
# sanity check
df %>% head()
county.df <- read_xlsx("../data/tidy/lsoa-to-county.xlsx")
county.df <- county.df[-2]
# change cols to lower
names(county.df) <- tolower(names(county.df))
# now to merge
df <- inner_join(df, county.df, by = "lsoa_code")
# sanity check
df$county %>% head()
# import the data
dwell.df <- read_xlsx("../data/raw/new-dwellings-started.xlsx")
# change cols to lower
names(dwell.df) <- tolower(names(dwell.df))
# now to merge
df <- inner_join(df, dwell.df, by = "county")
# sanity check
df %>% head()
# whilst this dataset looks great, lets sort the colnames alphabetically, as I'm very picky.
df <- df %>%
select(sort(current_vars()))
# sanity check as I'm tired
df %>% head()
# combined df
str(df)
# write.csv(df, file = "../data/nhs-data-full-df.csv")
head(df)
tail(df)
summary(df)
# create an empty vector
missingVals <- vector()
# start i at 0 as we're going to loop.
i = 0
# create the loop
for (i in 1:length(df)) {
missingVals[i] <-
paste("There are", sum(is.na(unlist(df[i]))), "missing values within", names(df[i]))
}
# print the unique values for each column.
print(missingVals)
# create an empty vector
uniqueVals <- vector()
# start i at 0 as we're going to loop.
i = 0
# create the loop
for (i in 1:length(df)) {
uniqueVals[i] <- paste("There are", length(unique(unlist(df[i]))), "unique values in", names(df[i]))
}
# print the unique values for each column.
print(uniqueVals)
# df$ageband[is.na(df$ageband)] <- mean(df$ageband, na.rm = TRUE) %>% round(0)
# df$ageband[is.na(df$ageband)] <- median(df$ageband, na.rm = TRUE) %>% round(0)
# df$ageband[is.na(df$ageband)] <- -10
# df$ageband[is.na(df$ageband)] <- 0
df <- drop_na(df)
# https://www.rdocumentation.org/packages/skimr/versions/2.1.3
library(skimr)
df %>% skim()
# we can produce some descriptive stats with profiling_num.
profiling_num(df)
# print to check the status of the data frame
status(df)
paste("The mean ageband is", mean(df$ageband) %>% round(2))
paste("The mean count is", mean(df$count) %>% round(2))
paste("The mean femalecount is", mean(df$femalecount) %>% round(2))
paste("The mean flats is", mean(df$flats) %>% round(2))
paste("The mean houses is", mean(df$houses) %>% round(2))
paste("The mean malecount is", mean(df$malecount) %>% round(2))
paste("The mean total is", mean(df$total) %>% round(2))
paste("The mean wimd_lsoa_rank is", mean(df$wimd_lsoa_rank) %>% round(2))
paste("The mean wimd_overall_decile is", mean(df$wimd_overall_decile) %>% round(2))
paste("The mean wimd_overall_quartile is", mean(df$wimd_overall_quartile) %>% round(2))
paste("The mean wimd_overall_quintile is", mean(df$wimd_overall_quintile) %>% round(2))
avg.lhb <- aggregate(formula = count ~ healthboard,
data = df,
FUN = mean)
# order it asc
avg.lhb[order(avg.lhb$count),]
med.lhb <- aggregate(formula = count ~ healthboard,
data = df,
FUN = median)
# order it asc
med.lhb[order(avg.lhb$count),]
library(readr)
pop_estimations <- read_csv("../data/web-scraping/pop-estimations.csv")
pop_estimations <- pop_estimations[-1]
avg.pop <- aggregate(formula = Total ~ `Health Board`,
data = pop_estimations,
FUN = mean)
avg.pop[order(avg.pop$Total),]
# average wimd
avg.wimd <- aggregate(formula = count ~ `wimd_lsoa_rank`,
data = df,
FUN = mean)
# order it asc
avg.wimd[order(avg.wimd$count, decreasing = T),]
med.wimd <- aggregate(formula = count ~ `wimd_lsoa_rank`,
data = df,
FUN = median)
# order it asc
med.wimd[order(med.wimd$count, decreasing = T),]
avg.county <- aggregate(formula = count ~ county,
data = df,
FUN = mean)
# order it asc
avg.county[order(avg.lhb$count, decreasing = T),]
med.county <- aggregate(formula = count ~ healthboard,
data = df,
FUN = median)
# order it asc
med.county[order(avg.lhb$count, decreasing = T),]
# frequency looks at plotting some of the numerical data
freq(df)
# numerical profiling in one function
# automatically excludes non-numerical variables
plot_num(df)
lhbs <- avg.lhb$healthboard
pp <- ggplot(avg.lhb, aes(count, healthboard, colour = healthboard)) +
geom_point(aes(size = 6)) +
labs(title = "Average Age Seen Per Health Board",
subtitle = "From 2020 - 2021")
pp
pp2 <- ggplot()
# plot the female visits
pp.female_visits <- df %>%
group_by(healthboard, ageband) %>%
summarise(femalecount = sum(femalecount),.groups = 'drop') %>%
ggplot(aes(x = ageband, y = femalecount, color = healthboard)) +
geom_line(size = 1.1) +
labs(title = str_to_title("Female Count by Ageband and Healthboard"),
subtitle = str_to_title("Number of visits per age"))
# plot the male visits
pp.male_visits <- df %>%
group_by(healthboard, ageband) %>%
summarise(malecount = sum(malecount),.groups = 'drop') %>%
ggplot(aes(x = ageband, y = malecount, color = healthboard)) +
geom_line(size = 1.1) +
labs(title = str_to_title("Male Count by Ageband and Healthboard"),
subtitle = str_to_title("Number of visits per age"))
pp.female_visits
pp.male_visits
pp.female_visits + pp.male_visits +
plot_layout(nrow = 2, guides = "collect")
# src https://stackoverflow.com/questions/69133366/replicate-excel-plot-with-ggplot2-in-r
# There's a dip around 18-20s - are they going to GPs in other areas
# are they even registering with a new GP if moving to uni?
# plot(df$wimd_lsoa_rank) + abline
# Min-Max normalisation
# create a function
min_max_norm <- function(x) {
(x - min(x)) / (max(x) - min(x))
}
# https://www.statology.org/how-to-normalize-data-in-r/
# CORRELATION TEST
# check a linear model for rank and count
wimdCountLM <- lm(df$wimd_lsoa_rank ~ df$count)
wimdCountLM$coefficients[1]
# first look at the data in a plot
ggplot(df, aes(wimd_lsoa_rank, count, colour = "pink")) +
geom_point(alpha = 0.5) +
geom_abline(aes(colour = "blue"),
intercept = wimdCountLM$coefficients[1],
slope = wimdCountLM$coefficients[2]) +
labs(title = str_to_title("Scatterplot of wimd lsoa rank and count"),
subtitle = str_to_title("Number of visits per year"),
x = str_to_title("wimd rank"),
y = str_to_title("gp visits")) +
theme(legend.position = "none")
# H0: Deprivation affects GP Visits
# H1: Deprivation doesn't affect GP Visits
cor.wimd.count <- cor(df$wimd_lsoa_rank, df$count, method = "spearman")
cor.wimd.count2 <- cor.test(df$wimd_lsoa_rank, df$count, method = "spearman")
summary(cor.wimd.count2)
# Tiny positive correlation
# My spearmans Rho was 0.001 demonstrating a tiny effect size Cohan, 1988.
# With a P value of 0.53 this relationship was not shown to be significantly significant
# T-TEST
ggplot(df, aes(count, year, color = as.factor(year))) +
geom_boxplot(aes(group = year)) +
labs(title = str_to_title("Boxplot of Count and Year"),
subtitle = str_to_title("Number of visits per year"),
x = str_to_title("gp visits"), y = str_to_title("year"),
color = "Year")
# H0: population variances are equal
library(car)
leveneTest(df$count ~ as.factor(df$year))
# Use Levene's test to check var.eq
t.test(df$count ~ df$year, var.eq = T)
# Make a boxplot of GP visits per county
ggplot(df, aes(count, county, color = as.factor(county))) +
geom_boxplot() + labs(title = str_to_title("Boxplot of gp visits and County"),
subtitle = str_to_title("Number of gp visits per county"),
x = str_to_title("gp visits"), y = str_to_title("year")) +
theme(legend.position = "none")
# Carry out an ANOVA for the number of GP visits per county
# mean
anovaCC <- aov(df$count ~ df$county)
summary(anovaCC)
# can also look at a Tukey test to see
# difference between all factor means
TukeyHSD(anovaCC) # can also be plotted %>% plot()
# Kruskal Wallis One-way ANOVA
# Used as a sanity check
kruskal.test(df$count ~ df$county)
lrmPlot <- ggplot(df, aes(total, count, color = as.factor(total))) +
geom_point() +
geom_abline(intercept = 79.43137074,
slope = 0.05265818) +
labs(title = str_to_title("Scatterplot of GP Visits against new properties"),
subtitle = str_to_title("GP Visits ~ Total number of new properties developed"),
x = str_to_title("New Properties Developed"),
y = str_to_title("GP Visits")) +
theme(legend.position = "none")
# H0: The intercept for our linear model is 0.
# H1: The intercept for our linear model isn't 0.
house.mod <- lm(count ~ total, data = df)
summary(house.mod)
# write.csv(df, "../data/tidy/full-gp-visits.csv")
df %>% aggregate(ageband)
df %>% aggregate(ageband,
fun = mean)
df %>% aggregate(ageband,
FUN = mean)
aggregate(df$ageband,FUN = mean)
aggregate(df$ageband,
by = df$healthboard,
FUN = mean)
aggregate(formula = ageband ~ healthboard,
data = df,
FUN = mean)
df$healthboard == "Swansea Bay UHB"
```{r}
aggregate(formula = ageband ~ healthboard,
data = df,
FUN = mean)
subset(df, df$healthboard == "Swansea Bay UHB")
swansea.df <- subset(df, df$healthboard == "Swansea Bay UHB")
swansea.df
plot(swansea.df)
plot(swansea.df$ageband)
summarise(swansea.df$ageband)
swansea.df$ageband
# T-TEST
ggplot(df, aes(count, year, color = as.factor(year))) +
geom_boxplot(aes(group = year)) +
labs(title = str_to_title("Boxplot of Count and Year"),
subtitle = str_to_title("Number of visits per year"),
x = str_to_title("gp visits"), y = str_to_title("year"),
color = "Year")
# H0: population variances are equal
library(car)
leveneTest(df$count ~ as.factor(df$year))
# Use Levene's test to check var.eq
t.test(df$count ~ df$year, var.eq = T)
glm(count ~ total, data = df)
lrmPlot <- ggplot(df, aes(total, count, color = as.factor(total))) +
geom_point() +
geom_abline(intercept = 79.43137074,
slope = 0.05265818) +
geom_smooth(method = "glm") +
labs(title = str_to_title("Scatterplot of GP Visits against new properties"),
subtitle = str_to_title("GP Visits ~ Total number of new properties developed"),
x = str_to_title("New Properties Developed"),
y = str_to_title("GP Visits")) +
theme(legend.position = "none")
# H0: The intercept for our linear model is 0.
# H1: The intercept for our linear model isn't 0.
house.mod <- lm(count ~ total, data = df)
summary(house.mod)
glm(count ~ total, data = df)
lrmPlot <- ggplot(df, aes(total, count, color = as.factor(total))) +
geom_point() +
geom_abline(intercept = 79.43137074,
slope = 0.05265818) +
geom_smooth(method = "glm") +
labs(title = str_to_title("Scatterplot of GP Visits against new properties"),
subtitle = str_to_title("GP Visits ~ Total number of new properties developed"),
x = str_to_title("New Properties Developed"),
y = str_to_title("GP Visits")) +
theme(legend.position = "none")
lrmPlot
lrmPlot <- ggplot(df, aes(total, count, color = as.factor(total))) +
geom_point() +
geom_abline(intercept = 79.43137074,
slope = 0.05265818) +
labs(title = str_to_title("Scatterplot of GP Visits against new properties"),
subtitle = str_to_title("GP Visits ~ Total number of new properties developed"),
x = str_to_title("New Properties Developed"),
y = str_to_title("GP Visits")) +
theme(legend.position = "none")
lrmPlot
# H0: The intercept for our linear model is 0.
# H1: The intercept for our linear model isn't 0.
house.mod <- lm(count ~ total, data = df)
summary(house.mod)
glm(count ~ total, data = df)
knitr::opts_chunk$set(
echo = FALSE,
message = TRUE,
warning = TRUE
)
library(car)
library(dplyr)
library(funModeling)
library(ggplot2)
library(patchwork)
library(readr)
library(readxl)
library(skimr)
library(tidyverse)
citation("car")
citation("dplyr")
citation("funModeling")
citation("ggplot2")
citation("knitr")
citation("patchwork")
citation("readr")
citation("readxl")
citation("rvest")
citation("skimr")
citation("taRifx")
citation("tidyverse")
